{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using POMDPTools\n",
    "using QuickPOMDPs\n",
    "using MCTS\n",
    "using POMDPSimulators\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "using D3Trees\n",
    "using Random\n",
    "using Plots\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "max_progress = 10\n",
    "max_power = 50\n",
    "max_h2o = 50\n",
    "max_o2 = 50\n",
    "max_food = 50\n",
    "\n",
    "# Uncertainties\n",
    "p_mission_regression = 0.05\n",
    "p_power_fail = 0.02\n",
    "p_water_loss = 0.02\n",
    "p_food_loss = 0.02\n",
    "p_no_mission_progress = 0.05\n",
    "\n",
    "# Resource consumption\n",
    "consumed_power = -2 # generated\n",
    "consumed_h2o = 1\n",
    "consumed_o2 = 1\n",
    "consumed_food = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all possible states and actions (with constraints)\n",
    "# [progress, power, h2o, o2, food]\n",
    "indexed = LinearIndices((max_progress, max_power, max_h2o, max_o2, max_food))\n",
    "states = 1:indexed[max_progress, max_power, max_h2o, max_o2, max_food]\n",
    "\n",
    "basic_actions = [\n",
    "      CartesianIndex(1, -3, 0, 0, 0), # make mission progress\n",
    "      CartesianIndex(0, -1, 8, 0, 0), # make water \n",
    "      CartesianIndex(0, -1, -1, 7, 0), # make oxygen\n",
    "      CartesianIndex(0, -1, -1, -1, 6), # make food\n",
    "      CartesianIndex(0, 0, 0, 0, 0) # do nothing\n",
    "] \n",
    "consumed = CartesianIndex(0, consumed_power, consumed_h2o, consumed_o2, consumed_food)\n",
    "actions = [action - consumed for action in basic_actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if action is out of bounds\n",
    "# Associated consequences are reflected in transition/reward functions\n",
    "state_maxes = [max_progress, max_power, max_h2o, max_o2, max_food]\n",
    "function inbounds(state, action)\n",
    "    for i in 1:length(state)\n",
    "        if (state[i] + action[i]) < 1\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    return true\n",
    "end\n",
    "\n",
    "function clamp_state(state)\n",
    "    for i in 1:length(state)\n",
    "        state[i] = clamp(state[i], 1, state_maxes[i])\n",
    "    end\n",
    "    return state\n",
    "end\n",
    "\n",
    "function cartesian2linear(svec)\n",
    "    return indexed[CartesianIndex(Tuple(svec))]\n",
    "end\n",
    "\n",
    "function linear2cartesian(s)\n",
    "    return CartesianIndices((max_progress, max_power, max_h2o, max_o2, max_food))[s]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is terminal?\n",
    "function isterminal(s)\n",
    "    svec = linear2cartesian(s)\n",
    "    end_state = svec[1] == max_progress # If reached a goal state\n",
    "    failed = all([any([(svec[i] + a[i]) < 1 for i in 1:length(svec)]) for a in actions]) # If all actions result in negative out of bounds (failed mission)\n",
    "    return end_state || failed \n",
    "end\n",
    "\n",
    "\n",
    "# Provide a list of valid actions\n",
    "function valid_actions(svec)\n",
    "    return [a for a in actions if !any([svec[i] + a[i] < 1 for i in 1:length(svec)])]\n",
    "end\n",
    "\n",
    "# Transition function\n",
    "function transition(s, a)\n",
    "    p_nominal = 1 - p_no_mission_progress - p_water_loss - p_power_fail - p_mission_regression \n",
    "    p = [p_no_mission_progress, p_water_loss, p_power_fail, p_mission_regression, p_nominal]\n",
    "\n",
    "    svec = collect(Tuple(linear2cartesian(s)))\n",
    "    a = collect(Tuple(a))\n",
    "    if !inbounds(svec, a)\n",
    "        a = collect(Tuple(last(actions))) # Try \"do nothing\"\n",
    "        if inbounds(svec, a) # If \"do nothing\" works\n",
    "            spvec = svec + a\n",
    "        else # If \"do nothing\" is not possible, choose a random action that is valid\n",
    "            possible_actions = valid_actions(svec)\n",
    "            a = collect(Tuple(rand(possible_actions)))\n",
    "            spvec = svec + a\n",
    "        end\n",
    "        sp = cartesian2linear(clamp_state(spvec))\n",
    "        return SparseCat([sp,], [1,])\n",
    "    else\n",
    "        spvec_no_mission_progress = svec + collect(Tuple(last(actions)))\n",
    "\n",
    "        spvec_water_loss = svec + a\n",
    "        spvec_water_loss[3] = round(0.5 * spvec_water_loss[3]) # lose all water\n",
    "\n",
    "        spvec_power_fail = svec + a\n",
    "        spvec_power_fail[2] = round(0.5 * spvec_power_fail[2]) # lose all energy\n",
    "\n",
    "        spvec_mission_regression = svec + a\n",
    "        spvec_mission_regression[1] = spvec_mission_regression[1] - 1 # mission setback\n",
    "\n",
    "        spvec_nominal = svec + a\n",
    "\n",
    "        spvec = [spvec_no_mission_progress, spvec_water_loss, spvec_power_fail, spvec_mission_regression, spvec_nominal]\n",
    "    end\n",
    "    \n",
    "    sp = []\n",
    "    for i in 1:length(p)\n",
    "        push!(sp, cartesian2linear(clamp_state(spvec[i])))\n",
    "    end\n",
    "    return SparseCat(sp, p)\n",
    "    \n",
    "end\n",
    "\n",
    "# Reward function\n",
    "function reward(s, a, sp)\n",
    "    svec = linear2cartesian(s)\n",
    "    spvec = linear2cartesian(sp)\n",
    "    if spvec[1] == max_progress\n",
    "        r = 1000000000000\n",
    "    elseif !inbounds(svec, a) # If invalid action\n",
    "        r = -100\n",
    "    else\n",
    "        r = -1\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_mdp(initialstate, states=states, actions=actions, discount=0.99, isterminal=isterminal, transition=transition, reward=reward)\n",
    "    return QuickMDP(\n",
    "        states = states,\n",
    "        actions = actions,\n",
    "        initialstate = initialstate,\n",
    "        discount = discount,\n",
    "        isterminal = isterminal,\n",
    "        transition = transition,\n",
    "        reward = reward\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simulate_mcts(initialstate, iter, rollout_iter, depth, replan_interval)\n",
    "\n",
    "    history = []\n",
    "    sarsp = Imatrix = zeros(Int, 4, 1)\n",
    "\n",
    "    s = initialstate\n",
    "    push!(history, s)\n",
    "    policy = rollout_policy(s, rollout_iter, depth)\n",
    "\n",
    "    for i in 1:iter\n",
    "\n",
    "        if isterminal(s)\n",
    "            break\n",
    "        end\n",
    "\n",
    "\n",
    "        if i % replan_interval == 0 # Replan\n",
    "            policy = rollout_policy(s, rollout_iter, depth )\n",
    "        end\n",
    "\n",
    "        a = action(policy, s)\n",
    "        T = transition(s, a)\n",
    "        sp = rand(T) \n",
    "        r = reward(s, a, sp)\n",
    "        a_ind = findfirst(item -> item == a, actions)\n",
    "        sarsp = hcat(sarsp, [indexed[s], a_ind, r, indexed[sp]])\n",
    "        push!(history, sp)\n",
    "        \n",
    "        s = sp\n",
    "\n",
    "    end\n",
    "    sarsp = sarsp[:, 2:end]\n",
    "    \n",
    "    return history, sarsp\n",
    "\n",
    "end\n",
    "\n",
    "function rollout_policy(state, rollout_iter, depth)\n",
    "    mdp = generate_mdp(state)\n",
    "    solver = MCTSSolver(n_iterations=rollout_iter, depth=depth, exploration_constant=5.0, enable_tree_vis=true)\n",
    "    policy = solve(solver, mdp)\n",
    "    return policy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a lot of data\n",
    "# The file is now empty\n",
    "open(\"MCTS_policy_sarsp.csv\", \"w\") do file  \n",
    "end\n",
    "\n",
    "open(\"MCTS_policy_steps.csv\", \"w\") do file  \n",
    "end\n",
    "\n",
    "for i in 1:40\n",
    "    initialstate = indexed[1, 10, 10, 10, 10]\n",
    "    history_var, sarsp = simulate_mcts(initialstate, 100, 1000, 100, 1)\n",
    "    CSV.write(\"MCTS_policy_history.csv\", Tables.table(history_var), append = true)\n",
    "\n",
    "    CSV.write(\"MCTS_policy_sarsp.csv\", Tables.table(sarsp'), header = [\"s\", \"a\", \"r\", \"s'\"], append = true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_var = [linear2cartesian(s) for s in history_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_progress = [s[1] / max_progress for s in history_var]\n",
    "history_power = [s[2] / max_power for s in history_var]\n",
    "history_h2o = [s[3] / max_h2o for s in history_var]\n",
    "history_o2 = [s[4] / max_o2 for s in history_var]\n",
    "history_food = [s[5] / max_food for s in history_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot()\n",
    "plot!(\n",
    "    p1,\n",
    "    1:length(history_var),\n",
    "    [history_progress history_power history_h2o history_o2 history_food],\n",
    "    label=[\"Progress\" \"Power\" \"H2O\" \"O2\" \"Food\"]\n",
    ")\n",
    "hline!(p1, [1], label=\"Progress Goal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random action (must be valid, only call when valid action exists)\n",
    "function random_action(s)\n",
    "    svec = linear2cartesian(s)\n",
    "    possible_actions = valid_actions(svec)\n",
    "    a = rand(possible_actions)\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simulate_random(initialstate, iter)\n",
    "    s = initialstate\n",
    "    sarsp = Imatrix = zeros(Int, 4, 1)\n",
    "    history = []\n",
    "    push!(history, s)\n",
    "    for _ in 1:iter\n",
    "        if isterminal(s)\n",
    "            break\n",
    "        end\n",
    "        a = random_action(s) # Choose valid action randomly\n",
    "        T = transition(s, a)\n",
    "        sp = rand(T)\n",
    "        r = reward(sp, a)\n",
    "        a_ind = findfirst(item -> item == a, actions)\n",
    "        sarsp = hcat(sarsp, [indexed[s], a_ind, r, indexed[sp]])\n",
    "        push!(history, sp)\n",
    "        s = sp\n",
    "    end\n",
    "\n",
    "    #delete first row again\n",
    "    sarsp = sarsp[:, 2:end]\n",
    "    return history, sarsp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_history, sarsp = simulate_random(initialstate, 100)\n",
    "rand_history = [linear2cartesian(s) for s in rand_history]\n",
    "rand_history_progress = [s[1] / max_progress for s in rand_history]\n",
    "rand_history_power = [s[2] / max_power for s in rand_history]\n",
    "rand_history_h2o = [s[3] / max_h2o for s in rand_history]\n",
    "rand_history_o2 = [s[4] / max_o2 for s in rand_history]\n",
    "rand_history_food = [s[5] / max_food for s in rand_history]\n",
    "p2 = plot()\n",
    "plot!(\n",
    "    p2,\n",
    "    1:length(rand_history),\n",
    "    [rand_history_progress rand_history_power rand_history_h2o rand_history_o2 rand_history_food],\n",
    "    label=[\"Mission Progress\" \"Power\" \"Water\" \"Oxygen\" \"Food\"]\n",
    ")\n",
    "hline!(p2, [1], label=\"Progress Goal\")\n",
    "\n",
    "savefig(p2, \"Mission Progress VS Resources Random.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for i in 1:100\n",
    "    rand_history, sarsp = simulate_random(initialstate, 100)\n",
    "    rand_history = [linear2cartesian(s) for s in rand_history]\n",
    "    rand_history_progress = [s[1] / max_progress for s in rand_history]\n",
    "    if (rand_history_progress[end] != 1)\n",
    "        push!(steps, 0)\n",
    "    else\n",
    "        push!(steps, length(rand_history))\n",
    "    end\n",
    "end\n",
    "\n",
    "CSV.write(\"random_policy.csv\", Tables.table(steps), append = false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"random_policy.csv\", DataFrame)\n",
    "Data = Matrix(df)\n",
    "histogram(Data; bins = 0:10:100, label=false, title = \"Steps until success simulated for 100 runs with initial conditions [1,10,10,10,10]\" )\n",
    "ylabel!(\"N\")\n",
    "xlabel!(\"Steps until success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a lot of data\n",
    "# The file is now empty\n",
    "open(\"random_policy_sarsp.csv\", \"w\") do file  \n",
    "end\n",
    "\n",
    "for i in 1:100\n",
    "    rand_history, sarsp = simulate_random(initialstate, 100)\n",
    "    rand_history = [linear2cartesian(s) for s in rand_history]\n",
    "    rand_history_progress = [s[1] / max_progress for s in rand_history]\n",
    "    if (rand_history_progress[end] != 1)\n",
    "        push!(steps, 0)\n",
    "    else\n",
    "        push!(steps, length(rand_history))\n",
    "    end\n",
    "    CSV.write(\"random_policy_sarsp.csv\", Tables.table(sarsp'), header = [\"s\", \"a\", \"r\", \"s'\"], append = true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"random_policy_sarsp.csv\", DataFrame)\n",
    "Data = Matrix(df)\n",
    "histogram(Data; bins = 0:10:100, label=false, title = \"Steps until success simulated for 100 runs with initial conditions [1,10,10,10,10]\" )\n",
    "ylabel!(\"N\")\n",
    "xlabel!(\"Steps until success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
